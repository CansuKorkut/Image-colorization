{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Explanation:\n",
    "#### The dataset consist of 90 images that are grouped into three categories: Source, Target, Groundtruth 30 images in each\n",
    "#### Source:  RGB images that are being used for training as y_train, while scource converted to grayscale are being used as X_train\n",
    "#### Target: grayscale images that are being used for prediction (we can say X_text)\n",
    "#### Groundtruth: RGB images that are being used for evaluation (we can say y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "from scipy.ndimage import uniform_filter\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from scipy.ndimage import uniform_filter\n",
    "warnings.filterwarnings('ignore') # to avoid showing warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Source Images and Extract Gray-scale Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create images and gray-scale images lists\n",
    "images = []\n",
    "gray_images = []\n",
    "\n",
    "# define minimum and maximum image index\n",
    "minImageIndex=1\n",
    "maxImageIndex=30\n",
    "\n",
    "for i in range(minImageIndex, maxImageIndex+1):\n",
    "    if i<=9:\n",
    "        # read bgr image and convert it to  rgb\n",
    "        image=cv2.imread(\"images/p00\"+str(i)+\", a_source.png\")[...,::-1]\n",
    "    else:\n",
    "        # read bgr image and convert it to  rgb\n",
    "        image = cv2.imread(\"images/p0\"+str(i)+\", a_source.png\")[...,::-1]\n",
    "\n",
    "    # resize the image to 1/9 of its size\n",
    "    image = cv2.resize(image, dsize=(image.shape[1]//9, image.shape[0]//9), interpolation=cv2.INTER_CUBIC)\n",
    "    \n",
    "    # extract the gray-scale image\n",
    "    gray_image =(0.299 * image[:,:,0] +  0.587 * image[:,:,1] + 0.114 * image[:,:,2]).astype('uint8')\n",
    "    \n",
    "    # add images and gray-scale images to their coressponding lists\n",
    "    images.append(image)\n",
    "    gray_images.append(gray_image)\n",
    "\n",
    "#show number of images we have\n",
    "print(\"Number of Images Loaded:\", len(images))\n",
    "print(\"Number of Gray-Scaled Images:\", len(gray_images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Feature Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# customized transformer that take gray-scale image, extract features and make it ready for training\n",
    "class FeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    " \n",
    "    def fit(self, X):\n",
    "        return self\n",
    " \n",
    "    def transform(self, X):\n",
    "        # make a copy of the image\n",
    "        X_ = X.copy().astype(float)\n",
    "        \n",
    "        # extract the mean of 3x3 window for each pixel\n",
    "        means= uniform_filter(X_, size=3, mode='constant')\n",
    "        \n",
    "        # extract the standard deviation of 3x3 window for each pixel\n",
    "        means1= cv2.blur(X_, (3, 3))\n",
    "        means2=cv2.blur(X_*X_, (3, 3))\n",
    "        stds=(means2-(means1*means1))**0.5\n",
    "        \n",
    "        # extract edges from the gray-scale image\n",
    "        edges = cv2.Canny((np.round(X*255)).astype('uint8'), 100, 200)\n",
    "        \n",
    "        # reshape each of the features to (nx1) shape\n",
    "        X_=X_.flatten().reshape(-1,1)\n",
    "        means=means.flatten().reshape(-1, 1)\n",
    "        stds=stds.flatten().reshape(-1, 1)\n",
    "        edges = edges.flatten().reshape(-1, 1)\n",
    "        \n",
    "        # stack the features horizontally \n",
    "        X_ = np.hstack((X_, means, stds, edges))\n",
    " \n",
    "        return X_ # (nx4) matrix\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create RGB Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# customized transformer that is used for shaping and reshaping RGB images\n",
    "class RgbTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, y):\n",
    "        return self\n",
    "\n",
    "    def transform(self, y):\n",
    "        # make a copy of the image\n",
    "        y_ = y.copy()\n",
    "        \n",
    "        # split the image into three channels red, green, and blue\n",
    "        y_r, y_g, y_b = y_[:,:,0], y_[:,:,1], y_[:,:,2]\n",
    "        \n",
    "        # reshape each of the channels to (nx1) shape\n",
    "        y_r=y_r.flatten().reshape(-1,1)\n",
    "        y_g=y_g.flatten().reshape(-1,1)\n",
    "        y_b=y_b.flatten().reshape(-1,1)\n",
    "        \n",
    "        # stack the channels horizontally\n",
    "        y_= np.hstack((y_r, y_g, y_b))\n",
    "\n",
    "        return y_ # (nx3) matrix\n",
    "    \n",
    "    def inverse_transform(self, y_pred, shape):\n",
    "        # make a copy of the image\n",
    "        y_pred_ = y_pred.copy()\n",
    "        \n",
    "        # reshape image\n",
    "        y_pred_ = y_pred_.reshape(shape)\n",
    "\n",
    "        return y_pred_ \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract Features and Shape Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features matrices\n",
    "X_trains = list(map(FeatureExtractor().fit_transform, gray_images))\n",
    "\n",
    "# extract targets(labels) matrices\n",
    "y_trains = list(map(RgbTransformer().fit_transform, images))\n",
    "\n",
    "print(\"number of images in training set:\", len(X_trains))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search Cross Validation On Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create regressors list\n",
    "Regressors = []\n",
    "\n",
    "# define parameters to be tested by grid search\n",
    "parameters = {'estimator__n_neighbors':range(1, 50, 2)}\n",
    "\n",
    "for i in tqdm(range(len(images))):\n",
    "    # define MultiOutput Regressor that use K-neighbors regressor as an estimator\n",
    "    regressor = MultiOutputRegressor(KNeighborsRegressor(), n_jobs=-1)\n",
    "    \n",
    "    # perform grid search on each image in training set\n",
    "    grid = GridSearchCV(regressor, parameters, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "    grid.fit(X_trains[i], y_trains[i])\n",
    "    \n",
    "    # add the best best estimator found by grid search to regressors list\n",
    "    Regressors.append(grid.best_estimator_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Target and Ground Truth Images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create grays, originals, and shapes lists\n",
    "grays = []\n",
    "originals = []\n",
    "shapes = [] # to be used later in forming predicted images\n",
    "\n",
    "for i in range(minImageIndex, maxImageIndex+1):\n",
    "    if i<=9:\n",
    "        # read gray-scale image\n",
    "        gray=cv2.imread(\"images/p00\"+str(i)+\", b_target.png\", cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        # read bgr image and convert it to rgb\n",
    "        original=cv2.imread(\"images/p00\"+str(i)+\", c_groundtruth.png\")[...,::-1]\n",
    "        \n",
    "    else:\n",
    "        # read gray-scale image\n",
    "        gray=cv2.imread(\"images/p0\"+str(i)+\", b_target.png\", cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        # read bgr image and convert it to rgb\n",
    "        original=cv2.imread(\"images/p0\"+str(i)+\", c_groundtruth.png\")[...,::-1]\n",
    "    \n",
    "    \n",
    "    # add original image, gray image, and shape to their coressponding lists\n",
    "    originals.append(original)\n",
    "    grays.append(gray)\n",
    "    shapes.append(original.shape)\n",
    "\n",
    "#show number of images we have  \n",
    "print(\"Number of Target Images Loaded:\", len(grays))\n",
    "print(\"Number of Ground Truth Images Loaded:\", len(originals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Features and Shape Testing Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Extract features matrices\n",
    "X_tests = [FeatureExtractor().fit_transform(gray) for gray in grays]\n",
    "\n",
    "# extract targets(labels) matrices\n",
    "y_tests = [RgbTransformer().fit_transform(original) for original in originals]\n",
    "\n",
    "print(\"number of images in testing set:\", len(X_tests))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create y_preds list\n",
    "y_preds = []\n",
    "for i in tqdm(range(len(X_tests))):\n",
    "    # predict for each image in testing set and add it to y_preds list\n",
    "    y_preds.append((np.round(Regressors[i].predict(X_tests[i]))).astype('uint8'))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shape the predicted images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_images = [RgbTransformer().inverse_transform(y_preds[i], shapes[i]) for i in range(len(y_preds))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# create plots grid\n",
    "fig, axs = plt.subplots(len(grays), 3, figsize=(15,200))\n",
    "\n",
    "# plot images\n",
    "for i in range(len(grays)):\n",
    "    axs[i,0].imshow(grays[i], cmap='gray') # plot target image\n",
    "    axs[i,1].imshow(originals[i]) # plot groundtruth image\n",
    "    axs[i,2].imshow(predicted_images[i]) # plot predicted image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and compute Mean Absolute Errors list\n",
    "mae_scores = [mean_absolute_error(y_tests[i],y_preds[i]) for i in range(len(y_preds))]\n",
    "\n",
    "# show Mean Absolute Error for each image\n",
    "for i in range(len(mae_scores)):\n",
    "    print('score for image',i+1,'is', mae_scores[i])\n",
    "print()\n",
    "\n",
    "# show the average Mean Absolute Error for all images\n",
    "print('average MAE for all images is',np.mean(mae_scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Regressors used for each Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
